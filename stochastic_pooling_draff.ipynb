{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syht/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import InputSpec\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import conv_utils, to_categorical\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops  \n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "import math\n",
    "import random\n",
    "random.seed(91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(StochasticPooling(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticPooling(Layer):\n",
    "    def __init__(self, pool_size=(2, 2), padding='SAME', data_format='channels_last', **kwargs):\n",
    "        super(StochasticPooling, self).__init__(**kwargs)\n",
    "        \n",
    "        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n",
    "        self.strides = conv_utils.normalize_tuple(pool_size, 2, 'strides')\n",
    "        self.padding = padding\n",
    "        self.data_format = 'NHWC' if data_format=='channels_last' else 'NCHW' \n",
    "        #conv_utils.normalize_data_format(data_format)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        \n",
    "    def _tf_pooling_function(self, x, name=None):\n",
    "        \n",
    "        def _pool(inputs, is_train):\n",
    "            start = time()\n",
    "            #assert np.min(inputs) > 0\n",
    "            ### min input into 0\n",
    "            inputs[inputs < 0] = 0\n",
    "            if np.sum(inputs) == 0:\n",
    "                inputs = np.random.rand(inputs.shape)\n",
    "            \n",
    "            input_shape = inputs.shape\n",
    "            batch, r, c, channel = input_shape[0], input_shape[1], input_shape[2], input_shape[3]\n",
    "            #print('Shape:', input_shape)\n",
    "\n",
    "            pr, pc = self.pool_size \n",
    "            sr, sc = self.strides\n",
    "\n",
    "            # compute number of windows\n",
    "            num_r =  math.ceil(r/sr) if self.padding == 'SAME' else r//sr\n",
    "            num_c = math.ceil(c/sc) if self.padding == 'SAME' else c//sc\n",
    "            \n",
    "            # reshape\n",
    "            w = np.transpose(inputs, (0, 3, 1, 2)) \n",
    "            w = np.reshape(w, (batch*channel, r, c))\n",
    "\n",
    "            def pool(x):                \n",
    "                if np.sum(x) == 0:\n",
    "                    cache = np.zeros((pr, pc))\n",
    "                    cache[0, 0] = 1.0\n",
    "                    return cache\n",
    "\n",
    "                x_prob = x / np.sum(x)\n",
    "                \n",
    "                if is_train:\n",
    "                    ### in forward pass\n",
    "                    # sort\n",
    "                    size = pr*pc\n",
    "                    x_prob = np.reshape(x_prob, [size])\n",
    "                    x_sorted = np.argsort(-x_prob)\n",
    "\n",
    "                    while True:\n",
    "                        h = random.randint(0, size - 1)\n",
    "                        y = random.random()\n",
    "\n",
    "                        p = x_sorted[h]\n",
    "\n",
    "                        if x_prob[p] >= y:\n",
    "                            break\n",
    "\n",
    "                    pool_matrix = np.zeros((pr, pc))\n",
    "                    pool_matrix[p//pr, p%pc] = 1.0\n",
    "\n",
    "                    return pool_matrix\n",
    "                else:\n",
    "                    return x_prob\n",
    "\n",
    "            re = np.zeros((batch*channel, num_r, num_c), dtype=np.float32)\n",
    "            # extract with pool_size\n",
    "            for i in range(num_r):\n",
    "                for j in range(num_c):\n",
    "                    crop = np.zeros((batch*channel, pr, pc))\n",
    "                    crop[:,:,:] = w[:, i*sr:i*sr+pr, j*sc:j*sc+pc]\n",
    "\n",
    "                    # pool\n",
    "                    outs = np.array(list(map(pool, crop)))\n",
    "                    \n",
    "                    if is_train:\n",
    "                        re[:, i, j] = (crop * outs).max(axis=(1,2))\n",
    "                    else:\n",
    "                        re[:, i, j] = (crop * outs).sum(axis=(1,2))\n",
    "\n",
    "            # reshape\n",
    "            re = np.reshape(re, (batch, channel, num_r, num_c))\n",
    "            re = np.transpose(re, (0, 2, 3, 1))\n",
    "            \n",
    "            #print(re.shape)\n",
    "            #print('Pool time:', time() - start)\n",
    "            #print(is_train)\n",
    "            return re\n",
    "\n",
    "        def custom_grad(op, grad):\n",
    "            if self.data_format=='NHWC':\n",
    "                ksizes=[1, self.pool_size[0], self.pool_size[1], 1]\n",
    "                strides=[1, self.strides[0], self.strides[1], 1]\n",
    "            else:\n",
    "                ksizes=[1, 1, self.pool_size[0], self.pool_size[1]]\n",
    "                strides=[1, 1, self.strides[0], self.strides[1]]\n",
    "            return gen_nn_ops.max_pool_grad_v2(\n",
    "                op.inputs[0],\n",
    "                op.outputs[0],\n",
    "                grad,\n",
    "                ksizes,\n",
    "                strides,\n",
    "                self.padding,\n",
    "                data_format=self.data_format\n",
    "            ), K.tf.constant(0.0)\n",
    "            \n",
    "            \"\"\"\n",
    "            inputs = op.inputs[0]\n",
    "            outputs = op.outputs[0]\n",
    "            \n",
    "            batch = K.shape(inputs)[0]\n",
    "            input_shape = K.int_shape(inputs)\n",
    "            r, c, channel = input_shape[1], input_shape[2], input_shape[3]\n",
    "            \n",
    "            pr, pc = self.pool_size \n",
    "            sr, sc = self.strides\n",
    "\n",
    "            # compute number of windows\n",
    "            num_r =  math.ceil(r/sr) if self.padding == 'SAME' else r//sr\n",
    "            num_c = math.ceil(c/sc) if self.padding == 'SAME' else c//sc\n",
    "            \n",
    "            # grad return\n",
    "            grad_re = K.tf.zeros_like(inputs)\n",
    "            \n",
    "            # transpose\n",
    "            grad_re = K.transpose(grad_re, perm=[0, 3, 1, 2])\n",
    "            inputs = K.transpose(inputs, perm=[0, 3, 1, 2])\n",
    "            outputs = K.transpose(outputs, perm=[0, 3, 1, 2])\n",
    "            \n",
    "            for i in range(num_r):\n",
    "                for j in range(num_c):\n",
    "                    crop = np.zeros((batch*channel, pr, pc))\n",
    "                    crop[:,:,:] = w[:, i*sr:i*sr+pr, j*sc:j*sc+pc]\n",
    "\n",
    "                    # pool\n",
    "                    outs = np.array(list(map(pool, crop)))\n",
    "                    \n",
    "                    if is_train:\n",
    "                        re[:, i, j] = (crop * outs).max(axis=(1,2))\n",
    "                    else:\n",
    "                        re[:, i, j] = (crop * outs).sum(axis=(1,2))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            mask = K.tf.where(K.tf.equal())\n",
    "            \n",
    "            \n",
    "            return grad_re, K.tf.constant(0.0)\n",
    "            \"\"\"\n",
    "\n",
    "        def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "            # Need to generate a unique name to avoid duplicates:\n",
    "            rnd_name = 'StochasticPoolingGrad' + str(np.random.randint(0, 1E+8))\n",
    "\n",
    "            K.tf.RegisterGradient(rnd_name)(grad)  \n",
    "            g = K.tf.get_default_graph()\n",
    "            with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "                return K.tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "        \n",
    "        with ops.name_scope(name, \"mod\", [x]) as name:\n",
    "            z = py_func(_pool,\n",
    "                        [x, K.tf.stop_gradient(K.in_train_phase(1, 0))],\n",
    "                        [K.tf.float32],\n",
    "                        name=name,\n",
    "                        grad=custom_grad)\n",
    "            \n",
    "            return z[0]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        r, c = input_shape[1], input_shape[2]\n",
    "        sr, sc = self.strides\n",
    "        num_r =  math.ceil(r/sr) if self.padding == 'SAME' else r//sr\n",
    "        num_c = math.ceil(c/sc) if self.padding == 'SAME' else c//sc\n",
    "        return (input_shape[0], num_r, num_c, input_shape[3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output = self._tf_pooling_function(inputs) #K.in_train_phase(self._tf_pooling_function(inputs), self._pooling_function_test(inputs))\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "                  'pool_size': self.pool_size,\n",
    "                  'strides': self.strides\n",
    "                }\n",
    "        base_config = super(StochasticPooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 24, 24, 16)        4624      \n",
      "_________________________________________________________________\n",
      "stochastic_pooling_49 (Stoch (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 301,274\n",
      "Trainable params: 301,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " 1640/60000 [..............................] - ETA: 1:14:35 - loss: 1.1199 - acc: 0.6250"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestStochasticPoolModel():\n",
    "    inputs = Input(shape=(65, 65, 3), name='input', dtype='float32')\n",
    "    conv = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    pool = StochasticPooling(padding='VALID')(conv)\n",
    "    #pool = MaxPool2D()(conv)\n",
    "    flat = Flatten()(pool)\n",
    "    dense = Dense(32, activation='relu')(flat)\n",
    "    out = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs, out)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "TestStochasticPoolModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 24, 24)\n",
      "(2048, 12, 12, 2, 2)\n",
      "13.69327688217163\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.rand(128, 24, 24, 16)\n",
    "\n",
    "padding = 'SAME'\n",
    "batch, r, c, channel = inputs.shape[0], inputs.shape[1], inputs.shape[2], inputs.shape[3]\n",
    "pr = 2\n",
    "pc = 2\n",
    "sr, sc = 2, 2\n",
    "num_r =  math.ceil(r/sr) if padding == 'SAME' else r//sr\n",
    "num_c = math.ceil(c/sc) if padding == 'SAME' else c//sc\n",
    "\n",
    "start = time()\n",
    "\n",
    "# reshape\n",
    "w = np.transpose(inputs, (0, 3, 1, 2)) \n",
    "w = np.reshape(w, (batch*channel, r, c))\n",
    "print(w.shape)\n",
    "\n",
    "def pool(x):\n",
    "    x_prob = x / np.sum(x)\n",
    "\n",
    "    ### in forward pass\n",
    "    # sort\n",
    "    size = pr*pc\n",
    "    x_prob = np.reshape(x_prob, [size])\n",
    "    x_sorted = np.argsort(-x_prob)\n",
    "\n",
    "    #print(x_prob)\n",
    "    while True:\n",
    "        h = random.randint(0, size - 1)\n",
    "        y = random.random()\n",
    "\n",
    "        p = x_sorted[h]\n",
    "\n",
    "        #print(h, y, p)\n",
    "        if x_prob[p] >= y:\n",
    "            break\n",
    "\n",
    "    cache = np.zeros((pr, pc))\n",
    "    cache[p//pr, p%pc] = 1.0\n",
    "\n",
    "    return cache #(np.reshape(x, [size])[p], \n",
    "\n",
    "re = np.zeros((batch*channel, num_r, num_c), dtype=np.float32)\n",
    "re_p = np.zeros((batch*channel, num_r, num_c, pr, pc), dtype=np.float32)\n",
    "# extract with pool_size\n",
    "for i in range(num_r):\n",
    "    for j in range(num_c):\n",
    "        crop = np.zeros((batch*channel, pr, pc))\n",
    "        crop[:,:,:] = w[:, i*sr:i*sr+pr, j*sc:j*sc+pc]\n",
    "\n",
    "        # pool\n",
    "        outs = np.array(list(map(pool, crop)))\n",
    "\n",
    "        re[:, i, j] = (crop * outs).max(axis=(1,2))\n",
    "        re_p[:, i, j] = outs\n",
    "\n",
    "# reshape\n",
    "re = np.reshape(re, (batch, channel, num_r, num_c))\n",
    "re = np.transpose(re, (0, 2, 3, 1))\n",
    "\n",
    "print(re_p.shape)\n",
    "\n",
    "\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def pooling_function(inputs):\n",
    "            \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            inputs : 4-tensor in format (batch size, rows, cols, channels), \n",
    "                    IMPORTANT: All values should be positive\n",
    "            \"\"\"\n",
    "            inputs[inputs < 0] = 0\n",
    "            if np.sum(inputs) == 0:\n",
    "                inputs = np.random.rand(inputs.shape)\n",
    "            \n",
    "            # get image shape\n",
    "            input_shape = inputs.shape\n",
    "            batch, r, c, channel = input_shape[0], input_shape[1], input_shape[2], input_shape[3]\n",
    "\n",
    "            pr, pc = self.pool_size \n",
    "            sr, sc = self.strides\n",
    "\n",
    "            # compute number of windows\n",
    "            num_r =  math.ceil(r/sr) if self.padding == 'SAME' else r//sr\n",
    "            num_c = math.ceil(c/sc) if self.padding == 'SAME' else c//sc\n",
    "\n",
    "            # apply pool\n",
    "            def stochastic_pool(x_crop):\n",
    "                #### calculate probabilities\n",
    "                x_prob = x_crop / K.sum(x_crop)\n",
    "\n",
    "                ### in forward pass\n",
    "                # sort\n",
    "                size = pr*pc\n",
    "                x_prob = K.reshape(x_prob, [size])\n",
    "                \n",
    "                x_sorted = K.tf.nn.top_k(x_prob, k=size, sorted=True).indices\n",
    "\n",
    "                # sample a position\n",
    "                y = 1.0 #K.tf.constant(1.0)\n",
    "                z_train = 0.0 # K.tf.constant(0.0)\n",
    "                x_position = 0 #K.tf.constant(0)\n",
    "\n",
    "                def sample(y, z_train, _):\n",
    "                    h = K.tf.constant(random.randint(0, size - 1))\n",
    "                    y = K.tf.constant(random.random())\n",
    "                    \n",
    "                    x_position = K.cast(K.tf.where(K.tf.equal(x_sorted, h))[0][0], 'int32')\n",
    "                        \n",
    "                    z_train = x_prob[x_position]\n",
    "                    \n",
    "                    return y, z_train, x_position\n",
    "                \n",
    "                _, _, x_position = K.tf.while_loop(lambda y, z_train, _: K.tf.less(z_train, y), sample, [y, z_train, x_position])\n",
    "\n",
    "                z = K.reshape(x_crop, [size])[x_position]\n",
    "                return z\n",
    "            \n",
    "            # transpose inputs into [batch, channel, col, row]\n",
    "            windows = K.tf.extract_image_patches(inputs, \n",
    "                                                ksizes=[1, pr, pc, 1], \n",
    "                                                strides=[1, sr, sc, 1], \n",
    "                                                rates=[1, 1, 1, 1], \n",
    "                                                padding=self.padding)\n",
    "\n",
    "            # reshape       \n",
    "            windows = K.reshape(windows, [-1, pr, pc, channel])\n",
    "            windows = K.tf.transpose(windows, perm=[0, 3, 1, 2]) \n",
    "            windows = K.reshape(windows, [batch*num_r*num_c*channel, pr, pc])\n",
    "\n",
    "            windows = K.tf.map_fn(stochastic_pool, windows)  \n",
    "            \n",
    "            # reshape\n",
    "            windows = K.reshape(windows, [batch*num_r*num_c, channel, 1])\n",
    "            windows = K.tf.transpose(windows, perm=[0, 2, 1])\n",
    "            windows = K.reshape(windows, [batch, num_r, num_c, channel])\n",
    "            \n",
    "            result = K.tf.Session(config=K.tf.ConfigProto(log_device_placement=True)).run(windows)\n",
    "            \n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pooling_function_test(self, inputs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : 4-tensor\n",
    "            in format (batch size, rows, cols, channels),\n",
    "            IMPORTANT: All values should be positive\n",
    "        \"\"\"\n",
    "        # get image shape\n",
    "        print(type(inputs))\n",
    "        batch = K.shape(inputs)[0]\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        r, c, channel = input_shape[1], input_shape[2], input_shape[3]\n",
    "        \n",
    "        pr, pc = self.pool_size \n",
    "        sr, sc = self.strides\n",
    "        \n",
    "        # compute number of windows\n",
    "        num_r =  math.ceil(r/sr) if self.padding == 'SAME' else r//sr\n",
    "        num_c = math.ceil(c/sc) if self.padding == 'SAME' else c//sc\n",
    "        \n",
    "        def _pool(x_crop):\n",
    "            #### calculate probabilities\n",
    "            x_prob = x_crop / K.sum(x_crop)\n",
    "            \n",
    "            ### in test phase, only take element wise multiply with the probabilities\n",
    "            return K.sum(K.tf.multiply(x_crop, x_prob))\n",
    "        \n",
    "        # transpose inputs into [batch, channel, col, row]\n",
    "        windows = K.tf.extract_image_patches(inputs, ksizes=[1, pr, pc, 1], \n",
    "                                          strides=[1, sr, sc, 1], rates=[1, 1, 1, 1], padding=self.padding)\n",
    "        \n",
    "        # reshape\n",
    "        origin_shape = K.shape(windows)        \n",
    "        windows = K.reshape(windows, [-1, pr, pc, channel])\n",
    "        windows = K.tf.transpose(windows, perm=[0, 3, 1, 2]) \n",
    "        windows = K.reshape(windows, [batch*num_r*num_c*channel, pr, pc])\n",
    "                \n",
    "        # apply pool\n",
    "        windows = K.tf.map_fn(_pool, windows)            \n",
    "        \n",
    "        # reshape\n",
    "        windows = K.reshape(windows, [batch*num_r*num_c, channel, 1])\n",
    "        windows = K.tf.transpose(windows, perm=[0, 2, 1])\n",
    "        windows = K.reshape(windows, [batch, num_r, num_c, channel])\n",
    "        \n",
    "        return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27348862 0.1686713  0.48607208 0.88841854]\n",
      " [0.15815645 0.66154016 0.43014945 0.89101383]\n",
      " [0.91413037 0.09411472 0.38693612 0.45047001]\n",
      " [0.2543991  0.25829275 0.51979136 0.09028198]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "List of Tensors when single Tensor expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-e2ec59972cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    381\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmismatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List of Tensors when single Tensor expected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "\u001b[0;31mTypeError\u001b[0m: List of Tensors when single Tensor expected"
     ]
    }
   ],
   "source": [
    "a = K.tf.constant(np.random.rand(4,4))\n",
    "print(K.eval(a))\n",
    "b = K.tf.constant([[a[1,1], a[1,3]], [a[3,1], a[3,3]]])\n",
    "print(K.eval(b))\n",
    "\n",
    "#a = K.reshape(a, [4])\n",
    "zeros = tf.zeros_like(a)\n",
    "ones = tf.ones_like(a)\n",
    "\n",
    "loc = K.tf.where(K.tf.equal(a, b), ones, zeros)\n",
    "print(K.eval(loc))\n",
    "\n",
    "K.eval(tf.boolean_mask(a,loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[[1, 3], [2, 5]], [[3, 1], [4, 7]]])\n",
    "b = tf.constant([1, 4])\n",
    "K.eval(tf.where(tf.equal(a, b), a, tf.zeros_like(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
