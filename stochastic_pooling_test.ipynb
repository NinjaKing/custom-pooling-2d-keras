{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syht/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import InputSpec\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import conv_utils, to_categorical\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from stochastic_pooling import *\n",
    "from mixed_pooling import *\n",
    "\n",
    "import math\n",
    "import random\n",
    "random.seed(91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1000, 28, 28, 1)\n",
      "1000 train samples\n",
      "100 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)[:1000,:,:,:]\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)[:100,:,:,:]\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train[:1000], num_classes)\n",
    "y_test = to_categorical(y_test[:100], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #model.add(StochasticPooling(pool_size=(2, 2), modify=False))\n",
    "    model.add(MixedPooling(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    #model.add(StochasticPooling(pool_size=(2, 2), modify=False))\n",
    "    model.add(MixedPooling(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train old alpha: [0. 0.]\n",
      "Train new alpha: [0.16135967 0.83864033]\n",
      "Test phase: [0.16135967 0.83864033]\n",
      "Train old alpha: [0. 0.]\n",
      "Train new alpha: [0.84432802 0.15567198]\n",
      "Test phase: [0.84432802 0.15567198]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "mixed_pooling_2 (MixedPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 16)        4624      \n",
      "_________________________________________________________________\n",
      "mixed_pooling_3 (MixedPoolin (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 80,090\n",
      "Trainable params: 80,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1287 - acc: 0.2620 - val_loss: 1.5586 - val_acc: 0.6000\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3764 - acc: 0.5380 - val_loss: 0.7004 - val_acc: 0.7800\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8830 - acc: 0.7010 - val_loss: 0.5150 - val_acc: 0.8600\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6882 - acc: 0.7780 - val_loss: 0.4216 - val_acc: 0.8400\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5929 - acc: 0.8140 - val_loss: 0.3621 - val_acc: 0.8600\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5101 - acc: 0.8300 - val_loss: 0.2449 - val_acc: 0.9400\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4468 - acc: 0.8670 - val_loss: 0.2028 - val_acc: 0.9600\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3937 - acc: 0.8710 - val_loss: 0.1718 - val_acc: 0.9600\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3531 - acc: 0.8920 - val_loss: 0.1732 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3187 - acc: 0.8960 - val_loss: 0.1581 - val_acc: 0.9500\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3079 - acc: 0.9130 - val_loss: 0.1470 - val_acc: 0.9600\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2675 - acc: 0.9140 - val_loss: 0.1281 - val_acc: 0.9500\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2308 - acc: 0.9380 - val_loss: 0.1028 - val_acc: 0.9700\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2489 - acc: 0.9150 - val_loss: 0.1181 - val_acc: 0.9800\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2047 - acc: 0.9350 - val_loss: 0.0856 - val_acc: 0.9600\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2074 - acc: 0.9340 - val_loss: 0.0952 - val_acc: 0.9800\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2015 - acc: 0.9400 - val_loss: 0.0896 - val_acc: 0.9600\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1847 - acc: 0.9440 - val_loss: 0.0793 - val_acc: 0.9600\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1671 - acc: 0.9410 - val_loss: 0.0859 - val_acc: 0.9600\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1669 - acc: 0.9450 - val_loss: 0.0889 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56c335ac88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_generator(X, y, batch_size=32):\n",
    "    while 1:\n",
    "        for i in range(math.ceil(len(X)/batch_size)):\n",
    "            X_batch = X[batch_size*i : batch_size*(i+1)]\n",
    "            y_batch = y[batch_size*i : batch_size*(i+1)]\n",
    "            \n",
    "            yield(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train = custom_generator(x_train, y_train, batch_size)\n",
    "gen_test = custom_generator(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 278s 9s/step - loss: 1.4846 - acc: 0.5290 - val_loss: 0.8102 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b886c57f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen_train, \n",
    "                        steps_per_epoch=math.ceil(len(x_train)/batch_size), \n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=gen_test, \n",
    "                        validation_steps=math.ceil(len(x_test)/batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
